{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: imports & environment (no Google API needed for HF embeddings)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "# FIXED: Import missing classes\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Load variables from .env\n",
    "load_dotenv()\n",
    "# Get token from .env\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "# Login securely\n",
    "login(hf_token)\n",
    "\n",
    "# Initialize HF embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 17\n",
      "First document preview: The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no ...\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load data from text, web, and PDF\n",
    "from langchain_community.document_loaders import TextLoader, WebBaseLoader, PyPDFLoader\n",
    "import bs4\n",
    "\n",
    "# Plain text\n",
    "loader = TextLoader(\"speech.txt\")\n",
    "text_documents = loader.load()\n",
    "\n",
    "# Web page (example)\n",
    "web_loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "        class_=(\"post-title\",\"post-content\",\"post-header\")\n",
    "    ))\n",
    ")\n",
    "web_documents = web_loader.load()\n",
    "\n",
    "# PDF\n",
    "pdf_loader = PyPDFLoader(\"attention.pdf\")\n",
    "pdf_docs = pdf_loader.load()\n",
    "\n",
    "# Combine all documents\n",
    "documents = []\n",
    "for d in (text_documents + web_documents + pdf_docs):\n",
    "    # Ensure each item is a Document object (LangChain format)\n",
    "    documents.append(d)\n",
    "    \n",
    "print(f\"Total documents loaded: {len(documents)}\")\n",
    "if documents:\n",
    "    print(f\"First document preview: {documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152,\n",
       " [Document(metadata={'source': 'speech.txt'}, page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.'),\n",
       "  Document(metadata={'source': 'speech.txt'}, page_content='Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\n…'),\n",
       "  Document(metadata={'source': 'speech.txt'}, page_content='…\\n\\nIt will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken from our hearts.')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Chunk documents into smaller pieces\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Inspect first few chunks\n",
    "len(documents), documents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store AFTER documents are chunked\n",
    "db = Chroma.from_documents(documents, embeddings, persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who are the authors of Attention is All You Need?\n",
      "A: Attention Visualizations\n",
      "Input-Input Layer5\n",
      "It\n",
      "is\n",
      "in\n",
      "this\n",
      "spirit\n",
      "that\n",
      "a\n",
      "majority\n",
      "of\n",
      "American\n",
      "governments\n",
      "have\n",
      "passed\n",
      "new\n",
      "laws\n",
      "since\n",
      "2009\n",
      "making\n",
      "the\n",
      "registration\n",
      "or\n",
      "voting\n",
      "process\n",
      "more\n",
      "difficult\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "It\n",
      "is\n",
      "in\n",
      "this\n",
      "spirit\n",
      "that\n",
      "a\n",
      "majority\n",
      "of\n",
      "American\n",
      "governments\n",
      "have\n",
      "passed\n",
      "new\n",
      "laws\n",
      "since\n",
      "2009\n",
      "making\n",
      "the\n",
      "registration\n",
      "or\n",
      "voting\n",
      "process\n",
      "more\n",
      "difficult\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "Figure 3: An example of the attention mechanism following long-distance dependencies in the\n",
      "encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\n",
      "the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\n"
     ]
    }
   ],
   "source": [
    "# Run some queries\n",
    "query = \"Who are the authors of Attention is All You Need?\"\n",
    "retrieved_results = db.similarity_search(query)\n",
    "print(\"Q:\", query)\n",
    "print(\"A:\", retrieved_results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Transformer architecture?\n",
      "A: Figure 1: The Transformer - model architecture.\n",
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
      "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
      "respectively.\n",
      "3.1 Encoder and Decoder Stacks\n",
      "Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\n",
      "sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\n",
      "wise fully connected feed-forward network. We employ a residual connection [11] around each of\n",
      "the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\n",
      "LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Transformer architecture?\"\n",
    "retrieved_results = db.similarity_search(query)\n",
    "print(\"Q:\", query)\n",
    "print(\"A:\", retrieved_results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
